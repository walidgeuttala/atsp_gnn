Namespace(data_dir='../tsp_input/generated_insatnces_3000_size_50/', tb_dir='../atsp_model_train_result', atsp_size=50, to_homo=True, half_st=False, model='EdgePropertyPredictionModel1', input_dim=1, hidden_dim=32, output_dim=1, relation_types='ss tt pp', n_gnn_layers=1, n_heads=1, jk='cat', lr_init=0.001, lr_decay=0.95, min_delta=0.0001, patience=200, batch_size=15, n_epochs=1, checkpoint_freq=10, seed=4, n_trials=1, n_samples_result_train=30, device='cuda')
Namespace(atsp_size=500, data_path='../tsp_input/generated_insatnces_100_size_500', model_path='../atsp_model_train_result/Oct20_15-06-46_EdgePropertyPredictionModel1_trained_ATSP50/trial_0', time_limit=0.16, perturbation_moves=5, device='cuda')
before uploading the test
GPU Memory Allocated: 0.00 MB
GPU Memory Cached: 0.00 MB
GPU Memory Free: 40377.25 MB
Total GPU Memory: 40377.25 MB
/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
after
GPU Memory Allocated: 0.00 MB
GPU Memory Cached: 0.00 MB
GPU Memory Free: 40377.25 MB
Total GPU Memory: 40377.25 MB
model: EdgePropertyPredictionModel1 trained in ATSP500 for 1 and tested in ATSP500 for 100
before the model
GPU Memory Allocated: 0.00 MB
GPU Memory Cached: 0.00 MB
GPU Memory Free: 40377.25 MB
Total GPU Memory: 40377.25 MB
after the model
GPU Memory Allocated: 0.12 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40375.13 MB
Total GPU Memory: 40377.25 MB
device = cuda
after the loading weights
GPU Memory Allocated: 0.49 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40374.76 MB
Total GPU Memory: 40377.25 MB
  0%|          | 0/100 [00:00<?, ?it/s]before loading the first sample
GPU Memory Allocated: 0.49 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40374.76 MB
Total GPU Memory: 40377.25 MB
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1480 KiB |   1480 KiB |   1480 KiB |      0 B   |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 B   |
|       from small pool |   1480 KiB |   1480 KiB |   1480 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |   1480 KiB |   1480 KiB |   1480 KiB |      0 B   |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 B   |
|       from small pool |   1480 KiB |   1480 KiB |   1480 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |   1356 KiB |   1356 KiB |   1356 KiB |      0 B   |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 B   |
|       from small pool |   1356 KiB |   1356 KiB |   1356 KiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|       from large pool |      0 KiB |      0 KiB |      0 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 581632 B   |   2047 KiB |   2047 KiB |   1479 KiB |
|       from large pool |      0 B   |      0 KiB |      0 KiB |      0 KiB |
|       from small pool | 581632 B   |   2047 KiB |   2047 KiB |   1479 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     363    |     363    |     363    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |     363    |     363    |     363    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     363    |     363    |     363    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |     363    |     363    |     363    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       1    |       1    |       1    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       1    |       1    |       1    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

after
GPU Memory Allocated: 1.45 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40373.80 MB
Total GPU Memory: 40377.25 MB
1
GPU Memory Allocated: 1.45 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40373.80 MB
Total GPU Memory: 40377.25 MB
2
GPU Memory Allocated: 40.03 MB
GPU Memory Cached: 120.00 MB
GPU Memory Free: 40217.22 MB
Total GPU Memory: 40377.25 MB
  0%|          | 0/100 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp_gnn/test.py", line 175, in <module>
    main(args_test)
  File "/project/p_gnn001/code/tsp/tsp_gnn/test.py", line 82, in main
    y_pred = model(H, x)
             ^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/gnngls/model.py", line 107, in forward
    h = l(G, h.detach()) + h.detach()
        ^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/gnngls/model_utils.py", line 58, in forward
    h = self.message_passing(x, G=G).view(G.number_of_nodes(), -1)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/gnngls/model_utils.py", line 32, in forward
    y = self.module(G, x).view(G.number_of_nodes(), -1)
        ^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/.local/lib/python3.11/site-packages/dgl/nn/pytorch/conv/gatconv.py", line 340, in forward
    graph.edata["a"] = self.attn_drop(edge_softmax(graph, e))
                                      ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/.local/lib/python3.11/site-packages/dgl/ops/edge_softmax.py", line 136, in edge_softmax
    return edge_softmax_internal(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/.local/lib/python3.11/site-packages/dgl/backend/pytorch/sparse.py", line 1116, in edge_softmax
    return EdgeSoftmax.apply(*args)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda121/lib/python3.11/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/.local/lib/python3.11/site-packages/dgl/backend/pytorch/sparse.py", line 711, in forward
    score = th.exp(_gsddmm(gidx, "sub", score, score_max, "e", "v"))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 39.43 GiB of which 1.50 GiB is free. Including non-PyTorch memory, this process has 37.93 GiB memory in use. Of the allocated memory 29.77 GiB is allocated by PyTorch, and 35.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
