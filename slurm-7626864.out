Namespace(data_dir='../tsp_input/generated_insatnces_3000_size_50/', tb_dir='../atsp_model_train_result', atsp_size=50, to_homo=False, half_st=False, model='HetroGATConcat', input_dim=1, hidden_dim=128, output_dim=1, relation_types='ss tt pp', n_gnn_layers=4, n_heads=64, jk='cat', lr_init=0.001, lr_decay=0.95, min_delta=0.0001, patience=200, batch_size=1, n_epochs=100, checkpoint_freq=10, seed=4, n_trials=1, n_samples_result_train=30, device='cuda')
the number of nodes that should be created 1176
max value 98
numbr of max tensor([48, 97], dtype=torch.int32)
m2 49 49
Number of nodes in type1: 98
number of nodes : 98
the number of nodes that should be created 1176
max value 98
numbr of max tensor([48, 97], dtype=torch.int32)
m2 49 49
Number of nodes in type1: 98
number of nodes : 98
device = cuda
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp_gnn/train.py", line 171, in <module>
    best_val_result, best_avg_gap_result, run_name = train(args, trial_id, run_name)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/train.py", line 118, in train
    result['train_loss'][epoch] = epoch_train(model, train_loader, criterion, optimizer, args.device)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/train.py", line 26, in epoch_train
    for batch_i, batch in enumerate(train_loader):
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
dgl._ffi.base.DGLError: Caught DGLError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/gnngls/datasets.py", line 205, in __getitem__
    H = self.get_scaled_features(G)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/gnngls/datasets.py", line 238, in get_scaled_features
    H.ndata['weight'] = torch.tensor(features_transformed, dtype=torch.float32).reshape(1, -1)
    ~~~~~~~^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/view.py", line 99, in __setitem__
    self._graph._set_n_repr(self._ntid, self._nodes, {key: val})
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/heterograph.py", line 4344, in _set_n_repr
    raise DGLError(
dgl._ffi.base.DGLError: Expect number of features to match number of nodes (len(u)). Got 1 and 98 instead.

