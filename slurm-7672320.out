Namespace(data_dir='../tsp_input/generated_insatnces_3000_size_50/', tb_dir='../atsp_model_train_result', atsp_size=50, to_homo=False, half_st=True, model='HetroGATConcat', input_dim=1, hidden_dim=128, output_dim=1, relation_types='ss tt pp', n_gnn_layers=4, n_heads=64, jk='cat', lr_init=0.001, lr_decay=0.95, min_delta=0.0001, patience=200, batch_size=15, n_epochs=100, checkpoint_freq=10, seed=4, n_trials=1, n_samples_result_train=30, device='cuda')
Namespace(atsp_size=1000, data_path='../tsp_input/generated_insatnces_100_size_1000', model_path='../atsp_model_train_result/Oct17_04-09-53_HetroGATConcat_trained_ATSP50/trial_0', time_limit=0.16, perturbation_moves=5, device='cuda')
model: HetroGATConcat trained in ATSP1000 for 100 and tested in ATSP1000 for 30
Using 2 GPUs!
device = cuda
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp_gnn/test.py", line 163, in <module>
    main(args_test)
  File "/project/p_gnn001/code/tsp/tsp_gnn/test.py", line 49, in main
    model.load_state_dict(checkpoint['model_state_dict'])
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2153, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for DataParallel:
	Missing key(s) in state_dict: "module.embed_layer.linears.0.weight", "module.embed_layer.linears.0.bias", "module.embed_layer.linears.1.weight", "module.embed_layer.linears.1.bias", "module.embed_layer.batch_norm.weight", "module.embed_layer.batch_norm.bias", "module.embed_layer.batch_norm.running_mean", "module.embed_layer.batch_norm.running_var", "module.gnn_layers.0.mods.ss.attn_l", "module.gnn_layers.0.mods.ss.attn_r", "module.gnn_layers.0.mods.ss.bias", "module.gnn_layers.0.mods.ss.fc.weight", "module.gnn_layers.0.mods.tt.attn_l", "module.gnn_layers.0.mods.tt.attn_r", "module.gnn_layers.0.mods.tt.bias", "module.gnn_layers.0.mods.tt.fc.weight", "module.gnn_layers.0.mods.pp.attn_l", "module.gnn_layers.0.mods.pp.attn_r", "module.gnn_layers.0.mods.pp.bias", "module.gnn_layers.0.mods.pp.fc.weight", "module.gnn_layers.1.mods.ss.attn_l", "module.gnn_layers.1.mods.ss.attn_r", "module.gnn_layers.1.mods.ss.bias", "module.gnn_layers.1.mods.ss.fc.weight", "module.gnn_layers.1.mods.tt.attn_l", "module.gnn_layers.1.mods.tt.attn_r", "module.gnn_layers.1.mods.tt.bias", "module.gnn_layers.1.mods.tt.fc.weight", "module.gnn_layers.1.mods.pp.attn_l", "module.gnn_layers.1.mods.pp.attn_r", "module.gnn_layers.1.mods.pp.bias", "module.gnn_layers.1.mods.pp.fc.weight", "module.gnn_layers.2.mods.ss.attn_l", "module.gnn_layers.2.mods.ss.attn_r", "module.gnn_layers.2.mods.ss.bias", "module.gnn_layers.2.mods.ss.fc.weight", "module.gnn_layers.2.mods.tt.attn_l", "module.gnn_layers.2.mods.tt.attn_r", "module.gnn_layers.2.mods.tt.bias", "module.gnn_layers.2.mods.tt.fc.weight", "module.gnn_layers.2.mods.pp.attn_l", "module.gnn_layers.2.mods.pp.attn_r", "module.gnn_layers.2.mods.pp.bias", "module.gnn_layers.2.mods.pp.fc.weight", "module.gnn_layers.3.mods.ss.attn_l", "module.gnn_layers.3.mods.ss.attn_r", "module.gnn_layers.3.mods.ss.bias", "module.gnn_layers.3.mods.ss.fc.weight", "module.gnn_layers.3.mods.tt.attn_l", "module.gnn_layers.3.mods.tt.attn_r", "module.gnn_layers.3.mods.tt.bias", "module.gnn_layers.3.mods.tt.fc.weight", "module.gnn_layers.3.mods.pp.attn_l", "module.gnn_layers.3.mods.pp.attn_r", "module.gnn_layers.3.mods.pp.bias", "module.gnn_layers.3.mods.pp.fc.weight", "module.mlp_layers.0.linears.0.weight", "module.mlp_layers.0.linears.0.bias", "module.mlp_layers.0.linears.1.weight", "module.mlp_layers.0.linears.1.bias", "module.mlp_layers.0.batch_norm.weight", "module.mlp_layers.0.batch_norm.bias", "module.mlp_layers.0.batch_norm.running_mean", "module.mlp_layers.0.batch_norm.running_var", "module.mlp_layers.1.linears.0.weight", "module.mlp_layers.1.linears.0.bias", "module.mlp_layers.1.linears.1.weight", "module.mlp_layers.1.linears.1.bias", "module.mlp_layers.1.batch_norm.weight", "module.mlp_layers.1.batch_norm.bias", "module.mlp_layers.1.batch_norm.running_mean", "module.mlp_layers.1.batch_norm.running_var", "module.mlp_layers.2.linears.0.weight", "module.mlp_layers.2.linears.0.bias", "module.mlp_layers.2.linears.1.weight", "module.mlp_layers.2.linears.1.bias", "module.mlp_layers.2.batch_norm.weight", "module.mlp_layers.2.batch_norm.bias", "module.mlp_layers.2.batch_norm.running_mean", "module.mlp_layers.2.batch_norm.running_var", "module.mlp_layers.3.linears.0.weight", "module.mlp_layers.3.linears.0.bias", "module.mlp_layers.3.linears.1.weight", "module.mlp_layers.3.linears.1.bias", "module.mlp_layers.3.batch_norm.weight", "module.mlp_layers.3.batch_norm.bias", "module.mlp_layers.3.batch_norm.running_mean", "module.mlp_layers.3.batch_norm.running_var", "module.decision_layer.linears.0.weight", "module.decision_layer.linears.0.bias", "module.decision_layer.linears.1.weight", "module.decision_layer.linears.1.bias", "module.decision_layer.batch_norm.weight", "module.decision_layer.batch_norm.bias", "module.decision_layer.batch_norm.running_mean", "module.decision_layer.batch_norm.running_var". 
	Unexpected key(s) in state_dict: "embed_layer.linears.0.weight", "embed_layer.linears.0.bias", "embed_layer.linears.1.weight", "embed_layer.linears.1.bias", "embed_layer.batch_norm.weight", "embed_layer.batch_norm.bias", "embed_layer.batch_norm.running_mean", "embed_layer.batch_norm.running_var", "embed_layer.batch_norm.num_batches_tracked", "gnn_layers.0.mods.ss.attn_l", "gnn_layers.0.mods.ss.attn_r", "gnn_layers.0.mods.ss.bias", "gnn_layers.0.mods.ss.fc.weight", "gnn_layers.0.mods.tt.attn_l", "gnn_layers.0.mods.tt.attn_r", "gnn_layers.0.mods.tt.bias", "gnn_layers.0.mods.tt.fc.weight", "gnn_layers.0.mods.pp.attn_l", "gnn_layers.0.mods.pp.attn_r", "gnn_layers.0.mods.pp.bias", "gnn_layers.0.mods.pp.fc.weight", "gnn_layers.1.mods.ss.attn_l", "gnn_layers.1.mods.ss.attn_r", "gnn_layers.1.mods.ss.bias", "gnn_layers.1.mods.ss.fc.weight", "gnn_layers.1.mods.tt.attn_l", "gnn_layers.1.mods.tt.attn_r", "gnn_layers.1.mods.tt.bias", "gnn_layers.1.mods.tt.fc.weight", "gnn_layers.1.mods.pp.attn_l", "gnn_layers.1.mods.pp.attn_r", "gnn_layers.1.mods.pp.bias", "gnn_layers.1.mods.pp.fc.weight", "gnn_layers.2.mods.ss.attn_l", "gnn_layers.2.mods.ss.attn_r", "gnn_layers.2.mods.ss.bias", "gnn_layers.2.mods.ss.fc.weight", "gnn_layers.2.mods.tt.attn_l", "gnn_layers.2.mods.tt.attn_r", "gnn_layers.2.mods.tt.bias", "gnn_layers.2.mods.tt.fc.weight", "gnn_layers.2.mods.pp.attn_l", "gnn_layers.2.mods.pp.attn_r", "gnn_layers.2.mods.pp.bias", "gnn_layers.2.mods.pp.fc.weight", "gnn_layers.3.mods.ss.attn_l", "gnn_layers.3.mods.ss.attn_r", "gnn_layers.3.mods.ss.bias", "gnn_layers.3.mods.ss.fc.weight", "gnn_layers.3.mods.tt.attn_l", "gnn_layers.3.mods.tt.attn_r", "gnn_layers.3.mods.tt.bias", "gnn_layers.3.mods.tt.fc.weight", "gnn_layers.3.mods.pp.attn_l", "gnn_layers.3.mods.pp.attn_r", "gnn_layers.3.mods.pp.bias", "gnn_layers.3.mods.pp.fc.weight", "mlp_layers.0.linears.0.weight", "mlp_layers.0.linears.0.bias", "mlp_layers.0.linears.1.weight", "mlp_layers.0.linears.1.bias", "mlp_layers.0.batch_norm.weight", "mlp_layers.0.batch_norm.bias", "mlp_layers.0.batch_norm.running_mean", "mlp_layers.0.batch_norm.running_var", "mlp_layers.0.batch_norm.num_batches_tracked", "mlp_layers.1.linears.0.weight", "mlp_layers.1.linears.0.bias", "mlp_layers.1.linears.1.weight", "mlp_layers.1.linears.1.bias", "mlp_layers.1.batch_norm.weight", "mlp_layers.1.batch_norm.bias", "mlp_layers.1.batch_norm.running_mean", "mlp_layers.1.batch_norm.running_var", "mlp_layers.1.batch_norm.num_batches_tracked", "mlp_layers.2.linears.0.weight", "mlp_layers.2.linears.0.bias", "mlp_layers.2.linears.1.weight", "mlp_layers.2.linears.1.bias", "mlp_layers.2.batch_norm.weight", "mlp_layers.2.batch_norm.bias", "mlp_layers.2.batch_norm.running_mean", "mlp_layers.2.batch_norm.running_var", "mlp_layers.2.batch_norm.num_batches_tracked", "mlp_layers.3.linears.0.weight", "mlp_layers.3.linears.0.bias", "mlp_layers.3.linears.1.weight", "mlp_layers.3.linears.1.bias", "mlp_layers.3.batch_norm.weight", "mlp_layers.3.batch_norm.bias", "mlp_layers.3.batch_norm.running_mean", "mlp_layers.3.batch_norm.running_var", "mlp_layers.3.batch_norm.num_batches_tracked", "decision_layer.linears.0.weight", "decision_layer.linears.0.bias", "decision_layer.linears.1.weight", "decision_layer.linears.1.bias", "decision_layer.batch_norm.weight", "decision_layer.batch_norm.bias", "decision_layer.batch_norm.running_mean", "decision_layer.batch_norm.running_var", "decision_layer.batch_norm.num_batches_tracked". 
