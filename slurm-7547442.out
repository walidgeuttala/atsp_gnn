Namespace(data_dir='../tsp_input/generated_insatnces_3000_size_50/', tb_dir='../atsp_model_train_result', atsp_size=50, to_homo=False, half_st=False, model='HetroGATConcat', input_dim=1, hidden_dim=128, output_dim=1, relation_types='ss st tt pp', n_gnn_layers=4, n_heads=64, jk='cat', lr_init=0.001, lr_decay=0.95, min_delta=0.0001, patience=200, batch_size=15, n_epochs=100, checkpoint_freq=10, seed=4, n_trials=1, n_samples_result_train=30, device='cuda')
Namespace(atsp_size=500, data_path='../tsp_input/generated_insatnces_30_size_500', model_path='../atsp_model_train_result/Oct15_14-45-35_HetroGATConcat_trained_ATSP50/trial_0', time_limit=0.16, perturbation_moves=5, device='cuda')
model: HetroGATConcat trained in ATSP50 for 100 and tested in ATSP500 for 30
device = cuda
  0%|          | 0/30 [00:00<?, ?it/s]  0%|          | 0/30 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "/project/p_gnn001/code/tsp/tsp_gnn/test.py", line 155, in <module>
    main(args_test)
  File "/project/p_gnn001/code/tsp/tsp_gnn/test.py", line 64, in main
    y_pred = model(H, x)
             ^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/p_gnn001/code/tsp/tsp_gnn/gnngls/model.py", line 69, in forward
    h2 = gnn_layer(graph, h1)
         ^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/nn/pytorch/hetero.py", line 210, in forward
    dstdata = self._get_module((stype, etype, dtype))(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/nn/pytorch/conv/gatconv.py", line 338, in forward
    e = self.leaky_relu(graph.edata.pop("e"))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 774, in forward
    return F.leaky_relu(input, self.negative_slope, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/nn/functional.py", line 1648, in leaky_relu
    result = torch._C._nn.leaky_relu(input, negative_slope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.81 GiB. GPU 0 has a total capacity of 39.43 GiB of which 11.32 GiB is free. Including non-PyTorch memory, this process has 28.11 GiB memory in use. Of the allocated memory 20.10 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
