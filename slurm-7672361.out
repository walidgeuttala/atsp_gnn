Namespace(data_dir='../tsp_input/generated_insatnces_3000_size_50/', tb_dir='../atsp_model_train_result', atsp_size=50, to_homo=True, half_st=False, model='EdgePropertyPredictionModel1', input_dim=1, hidden_dim=32, output_dim=1, relation_types='ss tt pp', n_gnn_layers=1, n_heads=1, jk='cat', lr_init=0.001, lr_decay=0.95, min_delta=0.0001, patience=200, batch_size=15, n_epochs=1, checkpoint_freq=10, seed=4, n_trials=1, n_samples_result_train=30, device='cuda')
Namespace(atsp_size=1000, data_path='../tsp_input/generated_insatnces_100_size_1000', model_path='../atsp_model_train_result/Oct20_15-06-46_EdgePropertyPredictionModel1_trained_ATSP50/trial_0', time_limit=0.16, perturbation_moves=5, device='cuda')
before uploading the test
GPU Memory Allocated: 0.00 MB
GPU Memory Cached: 0.00 MB
GPU Memory Free: 40377.25 MB
Total GPU Memory: 40377.25 MB
after
GPU Memory Allocated: 0.00 MB
GPU Memory Cached: 0.00 MB
GPU Memory Free: 40377.25 MB
Total GPU Memory: 40377.25 MB
model: EdgePropertyPredictionModel1 trained in ATSP1000 for 1 and tested in ATSP1000 for 30
before the model
GPU Memory Allocated: 0.00 MB
GPU Memory Cached: 0.00 MB
GPU Memory Free: 40377.25 MB
Total GPU Memory: 40377.25 MB
after the model
GPU Memory Allocated: 0.12 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40375.13 MB
Total GPU Memory: 40377.25 MB
device = cuda
after the loading weights
GPU Memory Allocated: 0.49 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40374.76 MB
Total GPU Memory: 40377.25 MB
  0%|          | 0/30 [00:00<?, ?it/s]before loading the first sample
GPU Memory Allocated: 0.49 MB
GPU Memory Cached: 2.00 MB
GPU Memory Free: 40374.76 MB
Total GPU Memory: 40377.25 MB
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  15224 MiB |  15224 MiB |  15224 MiB |      0 B   |
|       from large pool |  15224 MiB |  15224 MiB |  15224 MiB |      0 B   |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |  15224 MiB |  15224 MiB |  15224 MiB |      0 B   |
|       from large pool |  15224 MiB |  15224 MiB |  15224 MiB |      0 B   |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |  15224 MiB |  15224 MiB |  15224 MiB |      0 B   |
|       from large pool |  15224 MiB |  15224 MiB |  15224 MiB |      0 B   |
|       from small pool |      0 MiB |      0 MiB |      0 MiB |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  15246 MiB |  15246 MiB |  15246 MiB |      0 B   |
|       from large pool |  15244 MiB |  15244 MiB |  15244 MiB |      0 B   |
|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  21535 KiB |  21535 KiB |  22040 KiB | 516608 B   |
|       from large pool |  19992 KiB |  19992 KiB |  19992 KiB |      0 B   |
|       from small pool |   1543 KiB |   2047 KiB |   2047 KiB | 516608 B   |
|---------------------------------------------------------------------------|
| Allocations           |     365    |     365    |     365    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |     362    |     362    |     362    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |     365    |     365    |     365    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |     362    |     362    |     362    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

after
GPU Memory Allocated: 15224.97 MB
GPU Memory Cached: 15246.00 MB
GPU Memory Free: 9906.28 MB
Total GPU Memory: 40377.25 MB
1
GPU Memory Allocated: 15224.97 MB
GPU Memory Cached: 15246.00 MB
GPU Memory Free: 9906.28 MB
Total GPU Memory: 40377.25 MB
2
GPU Memory Allocated: 15355.09 MB
GPU Memory Cached: 15612.00 MB
GPU Memory Free: 9410.16 MB
Total GPU Memory: 40377.25 MB
terminate called after throwing an instance of 'c10::OutOfMemoryError'
  what():  CUDA out of memory. Tried to allocate 14.87 GiB. GPU 0 has a total capacity of 39.43 GiB of which 8.04 GiB is free. Including non-PyTorch memory, this process has 31.39 GiB memory in use. Of the allocated memory 29.86 GiB is allocated by PyTorch, and 12.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Exception raised from malloc at /opt/conda/conda-bld/pytorch_1708025824022/work/c10/cuda/CUDACachingAllocator.cpp:1125 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f9381e60d87 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x34e80 (0x7f9381f14e80 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x35124 (0x7f9381f15124 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x35328 (0x7f9381f15328 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #4: c10::cuda::CUDACachingAllocator::raw_alloc_with_stream(unsigned long, CUstream_st*) + 0x2c (0x7f930e1a6856 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_2.2.1.so)
frame #5: CUDARawAlloc + 0x30 (0x7f930e1a5ba8 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_2.2.1.so)
frame #6: dgl::runtime::CUDADeviceAPI::AllocDataSpace(DGLContext, unsigned long, unsigned long, DGLDataType) + 0x216 (0x7f930ed3f5e6 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #7: dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext) + 0x165 (0x7f930ebeb725 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #8: dgl::aten::NewIdArray(long, DGLContext, unsigned char) + 0x6d (0x7f930e71d91d in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #9: dgl::runtime::NDArray dgl::aten::impl::Range<(DGLDeviceType)2, long>(long, long, DGLContext) + 0x97 (0x7f930ed60037 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #10: dgl::aten::Range(long, long, unsigned char, DGLContext) + 0x1fd (0x7f930e71ed2d in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #11: std::pair<dgl::runtime::NDArray, dgl::runtime::NDArray> dgl::aten::impl::Sort<(DGLDeviceType)2, int>(dgl::runtime::NDArray, int) + 0x55 (0x7f930ed6bc85 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #12: dgl::aten::Sort(dgl::runtime::NDArray, int) + 0x502 (0x7f930e734c82 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #13: void dgl::aten::impl::COOSort_<(DGLDeviceType)2, int>(dgl::aten::COOMatrix*, bool) + 0x394 (0x7f930ed743e4 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #14: dgl::aten::COOSort_(dgl::aten::COOMatrix*, bool) + 0x38c (0x7f930e72ad4c in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #15: dgl::aten::COOSort(dgl::aten::COOMatrix, bool) + 0x45a (0x7f930e77ce1a in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #16: dgl::aten::CSRMatrix dgl::aten::impl::COOToCSR<(DGLDeviceType)2, int>(dgl::aten::COOMatrix) + 0x292 (0x7f930ed72742 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #17: dgl::aten::COOToCSR(dgl::aten::COOMatrix) + 0x4d3 (0x7f930e729e73 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #18: dgl::UnitGraph::GetInCSR(bool) const + 0xad (0x7f930ed0ba4d in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #19: dgl::UnitGraph::GetFormat(dgl::SparseFormat) const + 0x7d (0x7f930ed0cf2d in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #20: dgl::UnitGraph::InDegrees(unsigned long, dgl::runtime::NDArray) const + 0x36 (0x7f930ed0e006 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #21: dgl::HeteroGraph::InDegrees(unsigned long, dgl::runtime::NDArray) const + 0x49 (0x7f930ec30c79 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #22: <unknown function> + 0x88c751 (0x7f930ec3b751 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #23: DGLFuncCall + 0x4c (0x7f930ebd468c in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/libdgl.so)
frame #24: <unknown function> + 0x19f42 (0x7f930e196f42 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/_ffi/_cy3/core.cpython-312-x86_64-linux-gnu.so)
frame #25: <unknown function> + 0x1a6c4 (0x7f930e1976c4 in /home/p_gnngw/miniconda3/envs/cuda118/lib/python3.12/site-packages/dgl/_ffi/_cy3/core.cpython-312-x86_64-linux-gnu.so)
<omitting python frames>

/scratch/slurm/SlurmdSpoolDir/x1001c5s0b0n1/job7672361/slurm_script: line 41: 101928 Aborted                 (core dumped) python test.py
