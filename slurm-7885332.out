/project/c_gnn_001/conda_envs/cuda121/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
Namespace(data_dir='../tsp_input/generated_insatnces_3000_size_50/', tb_dir='../atsp_model_train_result', atsp_size=50, to_homo=True, half_st=False, model='EdgePropertyPredictionModel3', input_dim=1, hidden_dim=128, output_dim=1, relation_types='ss tt pp', n_gnn_layers=4, n_heads=64, jk='cat', lr_init=0.001, lr_decay=0.95, min_delta=0.0001, patience=200, batch_size=15, n_epochs=100, checkpoint_freq=10, seed=4, n_trials=1, n_samples_result_train=30, device='cuda')
device = cuda
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [01:15<?, ?it/s, avg_corr=0.8194, avg_corr_cosin=0.9720, avg_gap=17.5492, avg_init_cost=1890148.4667, avg_opt_cost=1607611.0333, epoch=0.0000, train_loss=0.0215, val_loss=0.0069]  1%|          | 1/100 [01:15<2:05:00, 75.76s/it, avg_corr=0.8194, avg_corr_cosin=0.9720, avg_gap=17.5492, avg_init_cost=1890148.4667, avg_opt_cost=1607611.0333, epoch=0.0000, train_loss=0.0215, val_loss=0.0069]  1%|          | 1/100 [02:18<2:05:00, 75.76s/it, avg_corr=0.8625, avg_corr_cosin=0.9778, avg_gap=17.1869, avg_init_cost=1882719.5333, avg_opt_cost=1607611.0333, epoch=1.0000, train_loss=0.0045, val_loss=0.0048]  2%|▏         | 2/100 [02:19<1:51:59, 68.57s/it, avg_corr=0.8625, avg_corr_cosin=0.9778, avg_gap=17.1869, avg_init_cost=1882719.5333, avg_opt_cost=1607611.0333, epoch=1.0000, train_loss=0.0045, val_loss=0.0048]  2%|▏         | 2/100 [03:20<1:51:59, 68.57s/it, avg_corr=0.8617, avg_corr_cosin=0.9757, avg_gap=13.6139, avg_init_cost=1826890.2333, avg_opt_cost=1607611.0333, epoch=2.0000, train_loss=0.0042, val_loss=0.0042]  3%|▎         | 3/100 [03:20<1:45:22, 65.18s/it, avg_corr=0.8617, avg_corr_cosin=0.9757, avg_gap=13.6139, avg_init_cost=1826890.2333, avg_opt_cost=1607611.0333, epoch=2.0000, train_loss=0.0042, val_loss=0.0042]  3%|▎         | 3/100 [04:19<1:45:22, 65.18s/it, avg_corr=0.8599, avg_corr_cosin=0.9772, avg_gap=21.4222, avg_init_cost=1958198.7667, avg_opt_cost=1607611.0333, epoch=3.0000, train_loss=0.0046, val_loss=0.0045]  4%|▍         | 4/100 [04:19<1:40:37, 62.90s/it, avg_corr=0.8599, avg_corr_cosin=0.9772, avg_gap=21.4222, avg_init_cost=1958198.7667, avg_opt_cost=1607611.0333, epoch=3.0000, train_loss=0.0046, val_loss=0.0045]  4%|▍         | 4/100 [05:20<1:40:37, 62.90s/it, avg_corr=0.8694, avg_corr_cosin=0.9794, avg_gap=23.4903, avg_init_cost=1993197.6000, avg_opt_cost=1607611.0333, epoch=4.0000, train_loss=0.0041, val_loss=0.0044]  5%|▌         | 5/100 [05:20<1:38:35, 62.27s/it, avg_corr=0.8694, avg_corr_cosin=0.9794, avg_gap=23.4903, avg_init_cost=1993197.6000, avg_opt_cost=1607611.0333, epoch=4.0000, train_loss=0.0041, val_loss=0.0044]  5%|▌         | 5/100 [06:22<1:38:35, 62.27s/it, avg_corr=0.8857, avg_corr_cosin=0.9811, avg_gap=13.1255, avg_init_cost=1822965.2000, avg_opt_cost=1607611.0333, epoch=5.0000, train_loss=0.0038, val_loss=0.0029]  6%|▌         | 6/100 [06:22<1:37:02, 61.94s/it, avg_corr=0.8857, avg_corr_cosin=0.9811, avg_gap=13.1255, avg_init_cost=1822965.2000, avg_opt_cost=1607611.0333, epoch=5.0000, train_loss=0.0038, val_loss=0.0029]  6%|▌         | 6/100 [07:22<1:37:02, 61.94s/it, avg_corr=0.8659, avg_corr_cosin=0.9759, avg_gap=12.1595, avg_init_cost=1797625.2333, avg_opt_cost=1607611.0333, epoch=6.0000, train_loss=0.0044, val_loss=0.0049]  7%|▋         | 7/100 [07:23<1:35:35, 61.68s/it, avg_corr=0.8659, avg_corr_cosin=0.9759, avg_gap=12.1595, avg_init_cost=1797625.2333, avg_opt_cost=1607611.0333, epoch=6.0000, train_loss=0.0044, val_loss=0.0049]  7%|▋         | 7/100 [08:23<1:35:35, 61.68s/it, avg_corr=0.8643, avg_corr_cosin=0.9747, avg_gap=13.9260, avg_init_cost=1836187.0000, avg_opt_cost=1607611.0333, epoch=7.0000, train_loss=0.0036, val_loss=0.0061]  8%|▊         | 8/100 [08:23<1:33:55, 61.25s/it, avg_corr=0.8643, avg_corr_cosin=0.9747, avg_gap=13.9260, avg_init_cost=1836187.0000, avg_opt_cost=1607611.0333, epoch=7.0000, train_loss=0.0036, val_loss=0.0061]  8%|▊         | 8/100 [09:21<1:33:55, 61.25s/it, avg_corr=0.8914, avg_corr_cosin=0.9824, avg_gap=15.8731, avg_init_cost=1868261.9333, avg_opt_cost=1607611.0333, epoch=8.0000, train_loss=0.0039, val_loss=0.0038]  9%|▉         | 9/100 [09:21<1:31:21, 60.24s/it, avg_corr=0.8914, avg_corr_cosin=0.9824, avg_gap=15.8731, avg_init_cost=1868261.9333, avg_opt_cost=1607611.0333, epoch=8.0000, train_loss=0.0039, val_loss=0.0038]  9%|▉         | 9/100 [10:21<1:31:21, 60.24s/it, avg_corr=0.8857, avg_corr_cosin=0.9768, avg_gap=18.5374, avg_init_cost=1910992.2000, avg_opt_cost=1607611.0333, epoch=9.0000, train_loss=0.0038, val_loss=0.0041] 10%|█         | 10/100 [10:21<1:30:14, 60.16s/it, avg_corr=0.8857, avg_corr_cosin=0.9768, avg_gap=18.5374, avg_init_cost=1910992.2000, avg_opt_cost=1607611.0333, epoch=9.0000, train_loss=0.0038, val_loss=0.0041] 10%|█         | 10/100 [11:20<1:30:14, 60.16s/it, avg_corr=0.8775, avg_corr_cosin=0.9756, avg_gap=15.0607, avg_init_cost=1853202.5333, avg_opt_cost=1607611.0333, epoch=10.0000, train_loss=0.0036, val_loss=0.0042] 11%|█         | 11/100 [11:20<1:28:27, 59.63s/it, avg_corr=0.8775, avg_corr_cosin=0.9756, avg_gap=15.0607, avg_init_cost=1853202.5333, avg_opt_cost=1607611.0333, epoch=10.0000, train_loss=0.0036, val_loss=0.0042] 11%|█         | 11/100 [12:20<1:28:27, 59.63s/it, avg_corr=0.8871, avg_corr_cosin=0.9772, avg_gap=17.0811, avg_init_cost=1887485.2667, avg_opt_cost=1607611.0333, epoch=11.0000, train_loss=0.0037, val_loss=0.0046] 12%|█▏        | 12/100 [12:20<1:27:52, 59.92s/it, avg_corr=0.8871, avg_corr_cosin=0.9772, avg_gap=17.0811, avg_init_cost=1887485.2667, avg_opt_cost=1607611.0333, epoch=11.0000, train_loss=0.0037, val_loss=0.0046] 12%|█▏        | 12/100 [13:18<1:27:52, 59.92s/it, avg_corr=0.8972, avg_corr_cosin=0.9828, avg_gap=12.4996, avg_init_cost=1811321.7000, avg_opt_cost=1607611.0333, epoch=12.0000, train_loss=0.0037, val_loss=0.0055] 13%|█▎        | 13/100 [13:18<1:26:04, 59.37s/it, avg_corr=0.8972, avg_corr_cosin=0.9828, avg_gap=12.4996, avg_init_cost=1811321.7000, avg_opt_cost=1607611.0333, epoch=12.0000, train_loss=0.0037, val_loss=0.0055] 13%|█▎        | 13/100 [14:18<1:26:04, 59.37s/it, avg_corr=0.8883, avg_corr_cosin=0.9818, avg_gap=14.8997, avg_init_cost=1846148.4000, avg_opt_cost=1607611.0333, epoch=13.0000, train_loss=0.0036, val_loss=0.0034] 14%|█▍        | 14/100 [14:18<1:25:20, 59.54s/it, avg_corr=0.8883, avg_corr_cosin=0.9818, avg_gap=14.8997, avg_init_cost=1846148.4000, avg_opt_cost=1607611.0333, epoch=13.0000, train_loss=0.0036, val_loss=0.0034] 14%|█▍        | 14/100 [15:17<1:25:20, 59.54s/it, avg_corr=0.8840, avg_corr_cosin=0.9796, avg_gap=13.1780, avg_init_cost=1820224.3333, avg_opt_cost=1607611.0333, epoch=14.0000, train_loss=0.0033, val_loss=0.0046] 15%|█▌        | 15/100 [15:17<1:23:50, 59.19s/it, avg_corr=0.8840, avg_corr_cosin=0.9796, avg_gap=13.1780, avg_init_cost=1820224.3333, avg_opt_cost=1607611.0333, epoch=14.0000, train_loss=0.0033, val_loss=0.0046] 15%|█▌        | 15/100 [16:16<1:23:50, 59.19s/it, avg_corr=0.8958, avg_corr_cosin=0.9829, avg_gap=12.7220, avg_init_cost=1811165.8667, avg_opt_cost=1607611.0333, epoch=15.0000, train_loss=0.0036, val_loss=0.0055] 16%|█▌        | 16/100 [16:16<1:22:57, 59.26s/it, avg_corr=0.8958, avg_corr_cosin=0.9829, avg_gap=12.7220, avg_init_cost=1811165.8667, avg_opt_cost=1607611.0333, epoch=15.0000, train_loss=0.0036, val_loss=0.0055] 16%|█▌        | 16/100 [17:15<1:22:57, 59.26s/it, avg_corr=0.8418, avg_corr_cosin=0.9736, avg_gap=18.8507, avg_init_cost=1919731.1333, avg_opt_cost=1607611.0333, epoch=16.0000, train_loss=0.0032, val_loss=0.0087] 17%|█▋        | 17/100 [17:15<1:21:39, 59.03s/it, avg_corr=0.8418, avg_corr_cosin=0.9736, avg_gap=18.8507, avg_init_cost=1919731.1333, avg_opt_cost=1607611.0333, epoch=16.0000, train_loss=0.0032, val_loss=0.0087] 17%|█▋        | 17/100 [18:15<1:21:39, 59.03s/it, avg_corr=0.8843, avg_corr_cosin=0.9783, avg_gap=17.3669, avg_init_cost=1894681.1333, avg_opt_cost=1607611.0333, epoch=17.0000, train_loss=0.0034, val_loss=0.0078] 18%|█▊        | 18/100 [18:15<1:21:20, 59.52s/it, avg_corr=0.8843, avg_corr_cosin=0.9783, avg_gap=17.3669, avg_init_cost=1894681.1333, avg_opt_cost=1607611.0333, epoch=17.0000, train_loss=0.0034, val_loss=0.0078] 18%|█▊        | 18/100 [19:15<1:21:20, 59.52s/it, avg_corr=0.8819, avg_corr_cosin=0.9781, avg_gap=13.9101, avg_init_cost=1834505.1000, avg_opt_cost=1607611.0333, epoch=18.0000, train_loss=0.0034, val_loss=0.0037] 19%|█▉        | 19/100 [19:15<1:20:16, 59.46s/it, avg_corr=0.8819, avg_corr_cosin=0.9781, avg_gap=13.9101, avg_init_cost=1834505.1000, avg_opt_cost=1607611.0333, epoch=18.0000, train_loss=0.0034, val_loss=0.0037] 19%|█▉        | 19/100 [20:16<1:20:16, 59.46s/it, avg_corr=0.8543, avg_corr_cosin=0.9709, avg_gap=15.2700, avg_init_cost=1856620.8333, avg_opt_cost=1607611.0333, epoch=19.0000, train_loss=0.0031, val_loss=0.0063] 20%|██        | 20/100 [20:16<1:19:54, 59.93s/it, avg_corr=0.8543, avg_corr_cosin=0.9709, avg_gap=15.2700, avg_init_cost=1856620.8333, avg_opt_cost=1607611.0333, epoch=19.0000, train_loss=0.0031, val_loss=0.0063]slurmstepd: error: *** JOB 7885332 ON x1001c7s1b0n1 CANCELLED AT 2024-10-24T00:36:14 ***
